{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9693d383-444d-42eb-b806-71c6712cf7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: fasttext-wheel in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from fasttext-wheel) (2.13.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from fasttext-wheel) (72.1.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\envs\\newgpuenv\\lib\\site-packages (from fasttext-wheel) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f74b81-611a-43aa-b2d3-ad54cb4c7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer # regexp tokenizers use to split words from text\n",
    "from nltk.stem.snowball import SnowballStemmer # stemmes words\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c121b9-be40-4b05-b1ef-6d4aff6535b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06871adf-5b2c-4f80-a513-5f35fb9ea7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1547c0b4-a274-4ebd-9265-9b04b1a3cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1cd0658-432f-42f3-acec-da96004da261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU(s) is/are being used.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only allocate memory as needed\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU(s) is/are being used.\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e7cf1e-3c9f-49dc-9063-422adce72dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b9bef83-875b-47e8-bb5c-cbc5c0a52068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b4ec6dc-930b-4b99-8448-6048b3bac38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d8706e2-9a82-4a2b-a389-c10e7c973cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be2f8693-d8e1-4bda-ad05-abaf4c42719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake = pd.read_csv('ISOTvfake news/Fake.csv')\n",
    "data_true = pd.read_csv('ISOTvfake news/True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "590b9699-4d91-4a14-9e4d-78f1b6b4e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake[\"class\"] = 0\n",
    "data_true[\"class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd617f19-8cfd-4cfb-a6d4-e13f0b431567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23481, 5), (21417, 5))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fake.shape, data_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e99a404-928d-4bfc-93d2-80fa5226236a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Racist Alabama Cops Brutalize Black Boy While...</td>\n",
       "      <td>The number of cases of cops brutalizing and ki...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fresh Off The Golf Course, Trump Lashes Out A...</td>\n",
       "      <td>Donald Trump spent a good portion of his day a...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 23, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trump Said Some INSANELY Racist Stuff Inside ...</td>\n",
       "      <td>In the wake of yet another court decision that...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 23, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Former CIA Director Slams Trump Over UN Bully...</td>\n",
       "      <td>Many people have raised the alarm regarding th...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WATCH: Brand-New Pro-Trump Ad Features So Muc...</td>\n",
       "      <td>Just when you might have thought we d get a br...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 21, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "5   Racist Alabama Cops Brutalize Black Boy While...   \n",
       "6   Fresh Off The Golf Course, Trump Lashes Out A...   \n",
       "7   Trump Said Some INSANELY Racist Stuff Inside ...   \n",
       "8   Former CIA Director Slams Trump Over UN Bully...   \n",
       "9   WATCH: Brand-New Pro-Trump Ad Features So Muc...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "5  The number of cases of cops brutalizing and ki...    News   \n",
       "6  Donald Trump spent a good portion of his day a...    News   \n",
       "7  In the wake of yet another court decision that...    News   \n",
       "8  Many people have raised the alarm regarding th...    News   \n",
       "9  Just when you might have thought we d get a br...    News   \n",
       "\n",
       "                date  class  \n",
       "0  December 31, 2017      0  \n",
       "1  December 31, 2017      0  \n",
       "2  December 30, 2017      0  \n",
       "3  December 29, 2017      0  \n",
       "4  December 25, 2017      0  \n",
       "5  December 25, 2017      0  \n",
       "6  December 23, 2017      0  \n",
       "7  December 23, 2017      0  \n",
       "8  December 22, 2017      0  \n",
       "9  December 21, 2017      0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge = pd.concat([data_fake, data_true], axis = 0)\n",
    "data_merge.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e79a7af-6a87-4751-bc86-ca627d98cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_merge.drop(['title', 'subject', 'date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ea80cb9-7bc6-4c95-bdf4-429817ab7853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3b569f8-62b1-4a6c-8c3b-1e61ff4cbb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac = 1)\n",
    "\n",
    "data.reset_index(inplace = True)\n",
    "data.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "131e685b-099c-4a31-8aea-f3930a81bd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAKAR (Reuters) - Suspected Christian militias...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAGHDAD (Reuters) - Iraqi lawmakers have reque...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump s attorney Jay Sekulow made a foo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On more than one occasion, Condoleezza Rice wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABUJA (Reuters) - Nigerian President Muhammadu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  DAKAR (Reuters) - Suspected Christian militias...      1\n",
       "1  BAGHDAD (Reuters) - Iraqi lawmakers have reque...      1\n",
       "2  Donald Trump s attorney Jay Sekulow made a foo...      0\n",
       "3  On more than one occasion, Condoleezza Rice wa...      0\n",
       "4  ABUJA (Reuters) - Nigerian President Muhammadu...      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "578456e3-767a-4546-8fb1-9517ce3aa88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]','', text) #remove text enclosed in square brackets, including the brackets themselves\n",
    "    text = re.sub(\"\\\\W\", \" \", text) #replaces all non-word characters (e.g., punctuation, special characters, symbols) with spaces\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # removes URLs from the text by matching and removing both HTTP/HTTPS URLs and \"www\" URLs\n",
    "    text = re.sub('<.*?>+', '', text) #remove HTML tags and their contents\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) #remove all punctuation characters\n",
    "    text = re.sub('\\n', '', text) #removes newline characters, which are typically used to represent line breaks or paragraphs in text\n",
    "    text = re.sub('\\w*\\d\\w', '', text) #removes words containing numbers or alphanumeric patterns\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7acd122-eb8f-4f8e-a13b-28f87a72789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(wordopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad6e8245-d5f0-4ef9-8257-43b8cac773b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[A-Za-z]+')#to getting alpha only\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "data['text'] = data.text.map(lambda t: tokenizer.tokenize(t))\n",
    "data['text'] = data.text.map(lambda l: [stemmer.stem(word) for word in l])\n",
    "data['text'] = data.text.map(lambda l: ' '.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "169277fa-9fe3-47ea-ba2d-38faad75e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dakar reuter suspect christian militia kill an...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baghdad reuter iraqi lawmak have request that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald trump s attorney jay sekulow made a foo...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on more than one occas condoleezza rice was ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abuja reuter nigerian presid muhammadu buhari ...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class class_label\n",
       "0  dakar reuter suspect christian militia kill an...      1  __label__1\n",
       "1  baghdad reuter iraqi lawmak have request that ...      1  __label__1\n",
       "2  donald trump s attorney jay sekulow made a foo...      0  __label__0\n",
       "3  on more than one occas condoleezza rice was ab...      0  __label__0\n",
       "4  abuja reuter nigerian presid muhammadu buhari ...      1  __label__1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class_label'] = \"__label__\" + data['class'].astype(str)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0d45577-cb4e-4e07-9db5-beb6ad1e37b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_label</th>\n",
       "      <th>class_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dakar reuter suspect christian militia kill an...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 dakar reuter suspect christian mili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baghdad reuter iraqi lawmak have request that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 baghdad reuter iraqi lawmak have re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald trump s attorney jay sekulow made a foo...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 donald trump s attorney jay sekulow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on more than one occas condoleezza rice was ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 on more than one occas condoleezza ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abuja reuter nigerian presid muhammadu buhari ...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 abuja reuter nigerian presid muhamm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class class_label  \\\n",
       "0  dakar reuter suspect christian militia kill an...      1  __label__1   \n",
       "1  baghdad reuter iraqi lawmak have request that ...      1  __label__1   \n",
       "2  donald trump s attorney jay sekulow made a foo...      0  __label__0   \n",
       "3  on more than one occas condoleezza rice was ab...      0  __label__0   \n",
       "4  abuja reuter nigerian presid muhammadu buhari ...      1  __label__1   \n",
       "\n",
       "                                          class_text  \n",
       "0  __label__1 dakar reuter suspect christian mili...  \n",
       "1  __label__1 baghdad reuter iraqi lawmak have re...  \n",
       "2  __label__0 donald trump s attorney jay sekulow...  \n",
       "3  __label__0 on more than one occas condoleezza ...  \n",
       "4  __label__1 abuja reuter nigerian presid muhamm...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class_text'] = data['class_label'] + \" \" + data['text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8c777a4-484c-4722-903c-4762773833b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a3eb577-c0fa-437b-bf29-538540fd138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = 0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ff637b9-645c-40d0-b6f6-431068cab913",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['text'], data['class'], test_size=0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de49a8c8-2015-4958-ab4c-f8d43959689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"news.train\", columns=[\"class_text\"], index=False, header=False)\n",
    "test.to_csv(\"news.test\", columns=[\"class_text\"], index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9783bb8c-2e9c-4222-83d7-d029e01ec15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11225, 0.9906458797327394, 0.9906458797327394)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = fasttext.train_supervised(input=\"news.train\")\n",
    "# model.test(\"news.test\")\n",
    "model = fasttext.train_supervised(input=\"news.train\")\n",
    "model.test(\"news.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "999fdc9d-b807-4c27-a5f1-d6cf6e9a590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"news_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "891ca515-08b2-4cf5-b9e0-e0d4d477470e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model('news_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5420e5a4-8c15-40d6-8417-0877bbef2805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__0',), array([0.99992776]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('Donald Trump spent a good portion of his day at his golf club, marking the 84th day he s done so since taking the oath of office. It must have been a bad game because just after that, Trump lashed out at FBI Deputy Director Andrew McCabe on Twitter following a report saying McCabe plans to retire in a few months. The report follows McCabe s testimony in front of congressional committees this week, as well as mounting criticism from Republicans regarding the Russia probe.So, naturally, Trump attacked McCabe with a lie. How can FBI Deputy Director Andrew McCabe, the man in charge, along with leakin  James Comey, of the Phony Hillary Clinton investigation (including her 33,000 illegally deleted emails) be given $700,000 for wife s campaign by Clinton Puppets during investigation?  Trump tweeted.How can FBI Deputy Director Andrew McCabe, the man in charge, along with leakin  James Comey, of the Phony Hillary Clinton investigation (including her 33,000 illegally deleted emails) be given $700,000 for wife s campaign by Clinton Puppets during investigation?  Donald J. Trump (@realDonaldTrump) December 23, 2017He didn t stop there.FBI Deputy Director Andrew McCabe is racing the clock to retire with full benefits. 90 days to go?!!!  Donald J. Trump (@realDonaldTrump) December 23, 2017Wow,  FBI lawyer James Baker reassigned,  according to @FoxNews.  Donald J. Trump (@realDonaldTrump) December 23, 2017With all of the Intel at Trump s disposal, he s getting his information from Fox News. McCabe spent most of his career in the fight against terrorism and now he s being attacked by the so-called president. Trump has been fact-checked before on his claim of his wife receiving $700,000 for her campaign.Politifact noted in late July that Trump s  tweet about Andrew McCabe is a significant distortion of the facts. And the implication that McCabe got Clinton off as a political favor doesn t make much sense when we look at the evidence. His July tweet was rated  mostly false.  But Trump repeats these lies because he knows his supporters will believe them without bothering to Google. It s still a lie, though.Photo by Zach Gibson   Pool/Getty Images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc8b1673-5c10-49c4-b4ca-5b61a8b2e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vocabulary and embeddings\n",
    "vocabulary = model.get_words()\n",
    "word_embeddings = np.array([model.get_word_vector(word) for word in vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eae36e4a-8930-463e-bd5b-b32463eca073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding matrix\n",
    "embedding_dim = model.get_dimension()  # Dimension of FastText embeddings\n",
    "embedding_matrix = np.zeros((len(vocabulary), embedding_dim))\n",
    "for i, word in enumerate(vocabulary):\n",
    "    embedding_matrix[i] = model.get_word_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3d9ba3f-f314-4319-87c8-3f9d1ea6075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embedding matrix to a file\n",
    "np.save('embedding_matrix.npy', embedding_matrix)  #file is in the NumPy array format as .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e946d4d1-b02c-4795-a3e9-e3a48a681524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "512ba96c-f95a-4885-b669-71bc05a8451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18406124\n"
     ]
    }
   ],
   "source": [
    "text_column = data['text']\n",
    "\n",
    "# Concatenate all the text data into a single string\n",
    "all_text = ' '.join(text_column)\n",
    "\n",
    "# Split the text into words and count them\n",
    "word_count = len(all_text.split())\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8978db2e-9734-431e-a945-5916256cdd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 0\n",
    "for text in text_column:\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    sequence_length = len(tokens)\n",
    "    max_sequence_length = max(max_sequence_length, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07c98fe6-24ab-4087-9141-4051620a4d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8280\n"
     ]
    }
   ],
   "source": [
    "print(max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7c68f57-71b4-459e-8556-e814c8ed9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocabulary)\n",
    "sequence_length = max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e513eb0e-b4f9-46a9-b332-0d7e3bc9d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74818, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c368166c-05fa-4266-9164-e1218d62eb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21a6a8a7-b129-4b90-b026-537ba997a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas Series to NumPy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b0fb20d-638d-4374-bbec-6cad3bfaa68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train type: <class 'numpy.ndarray'>\n",
      "x_train shape: (33673,)\n",
      "y_train type: <class 'numpy.ndarray'>\n",
      "y_train shape: (33673,)\n",
      "x_test type: <class 'numpy.ndarray'>\n",
      "x_test shape: (11225,)\n",
      "y_test type: <class 'numpy.ndarray'>\n",
      "y_test shape: (11225,)\n"
     ]
    }
   ],
   "source": [
    "# Check the data types and shapes to verify they are suitable\n",
    "print(\"x_train type:\", type(x_train))\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train type:\", type(y_train))\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test type:\", type(x_test))\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test type:\", type(y_test))\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37b92ca7-f8ca-4660-ab73-4022940001f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe45c6d1-c4df-47e3-ada7-9ad7df79375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)  # Assuming x_train is a list of text strings\n",
    "x_train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Pad sequences\n",
    "x_train_padded = pad_sequences(x_train_sequences, maxlen=sequence_length)\n",
    "x_test_padded = pad_sequences(x_test_sequences, maxlen=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9848e858-a435-4c11-8f21-29257bdb6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Concatenate, GlobalMaxPooling1D, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3074a213-8ecc-497e-b13b-fa9c807fde30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8280)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 8280, 100)    7481800     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 8278, 128)    38528       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 8277, 128)    51328       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 8276, 128)    64128       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 4139, 128)    0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 4138, 128)   0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 4138, 128)   0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 12415, 128)   0           ['max_pooling1d[0][0]',          \n",
      "                                                                  'max_pooling1d_1[0][0]',        \n",
      "                                                                  'max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 12413, 128)   49280       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 6206, 128)   0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 6204, 128)    49280       ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 3102, 128)   0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['max_pooling1d_4[0][0]']        \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          16512       ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,750,985\n",
      "Trainable params: 269,185\n",
      "Non-trainable params: 7,481,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "input_layer = Input(shape=(sequence_length,))\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "\n",
    "# Convolutional layers\n",
    "conv1d = Conv1D(filters=128, kernel_size=3, activation='relu')(embedding)\n",
    "conv1d_1 = Conv1D(filters=128, kernel_size=4, activation='relu')(embedding)\n",
    "conv1d_2 = Conv1D(filters=128, kernel_size=5, activation='relu')(embedding)\n",
    "\n",
    "# MaxPooling layers\n",
    "max_pooling1d = MaxPooling1D(pool_size=2)(conv1d)\n",
    "max_pooling1d_1 = MaxPooling1D(pool_size=2)(conv1d_1)\n",
    "max_pooling1d_2 = MaxPooling1D(pool_size=2)(conv1d_2)\n",
    "\n",
    "# Concatenate max-pooled layers\n",
    "concatenated = Concatenate(axis=1)([max_pooling1d, max_pooling1d_1, max_pooling1d_2])\n",
    "\n",
    "# Additional Convolutional and MaxPooling layers\n",
    "conv1d_3 = Conv1D(filters=128, kernel_size=3, activation='relu')(concatenated)\n",
    "max_pooling1d_3 = MaxPooling1D(pool_size=2)(conv1d_3)\n",
    "conv1d_4 = Conv1D(filters=128, kernel_size=3, activation='relu')(max_pooling1d_3)\n",
    "max_pooling1d_4 = MaxPooling1D(pool_size=2)(conv1d_4)\n",
    "\n",
    "# GlobalMaxPooling layer\n",
    "global_max_pooling1d = GlobalMaxPooling1D()(max_pooling1d_4)\n",
    "\n",
    "# Dense layers\n",
    "dense = Dense(128, activation='relu')(global_max_pooling1d)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense)  # Assuming binary classification\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model (specify loss, optimizer, and metrics)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Define model checkpoint\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c774917-f61a-4c22-9ba3-9498c50dcbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1684/1684 [==============================] - 530s 311ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.0187 - val_accuracy: 0.9952\n",
      "Epoch 2/5\n",
      "1684/1684 [==============================] - 516s 306ms/step - loss: 0.0136 - accuracy: 0.9967 - val_loss: 0.0133 - val_accuracy: 0.9963\n",
      "Epoch 3/5\n",
      "1684/1684 [==============================] - 514s 305ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.0153 - val_accuracy: 0.9960\n",
      "Epoch 4/5\n",
      "1684/1684 [==============================] - 521s 309ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
      "Epoch 5/5\n",
      "1684/1684 [==============================] - 557s 331ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.0111 - val_accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2166e902d30>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_padded, y_train, validation_data=(x_test_padded, y_test), epochs=5, batch_size=20, callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e288006-948c-43a5-a8e9-169fff478120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 51s 144ms/step - loss: 0.0111 - accuracy: 0.9975\n",
      "Test Loss: 0.0111327413469553, Test Accuracy: 0.9975055456161499\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7703488b-0da6-4c96-824b-c33c8d174d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/fasttext-cnn-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "181fa45f-e71f-438d-a72d-152ff1d50aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 391ms/step\n",
      "['fake']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'[A-Za-z]+') #to getting alpha only\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Tokenize and preprocess the new input data\n",
    "new_input_data = [ \"BREAKING : Trump Expressed Concern Over Anthony Weinerâ€™s â€œIllegal Accessâ€ to Classified Info 2 Months ago BREAKING : Trump Expressed Concern Over Anthony Weinerâ€™s â€œIllegal Accessâ€ to Classified Info 2 Months ago Breaking News By Amy Moreno October 28, 2016. Once again, Trump was right. Back in August, in a statement regarding Hillaryâ€™s carelessness handling classified documents, Trump stated that he was concerned that Weiner had â€œaccessâ€ to information he shouldnâ€™t. Now that weâ€™re learning that the FBI discovered â€œnew emailsâ€ on a â€œdeviceâ€ associated to Weiner, it looks as if Trump was right AGAIN. â€” Deplorable AJ (@asamjulian) October 28, 2016 This is a movement â€“ we are the political OUTSIDERS fighting against the FAILED GLOBAL ESTABLISHMENT! Join the resistance and help us fight to put America First! Amy Moreno is a Published Author , Pug Lover & Game of Thrones Nerd. You can follow her on Twitter here and Facebook here . Support the Trump Movement and help us fight Liberal Media Bias. Please LIKE and SHARE this story on Facebook or Twitter.  \"]\n",
    "new_sequences = [wordopt(sentence) for sentence in new_input_data]\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer1 = Tokenizer()\n",
    "tokenizer1.fit_on_texts(new_sequences)  # Assuming x_train is a list of text strings\n",
    "new_sequences = tokenizer1.texts_to_sequences(new_sequences)\n",
    "\n",
    "# Pad sequences\n",
    "new_sequences = pad_sequences(new_sequences, maxlen=sequence_length)\n",
    "\n",
    "# new_sequences = [map_tokens_to_indices(sequence, embedding_matrix, sequence_length) for sequence in new_sequences]\n",
    "\n",
    "# Convert 'new_sequences' to a NumPy array\n",
    "new_data = np.array(new_sequences)\n",
    "\n",
    "# Pad or truncate the sequences to match the sequence length\n",
    "new_data = pad_sequences(new_data, maxlen=sequence_length, padding='post', truncating='post')\n",
    "\n",
    "# Make predictions on the new data\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# The 'predictions' array will contain probability scores for each class (0 and 1)\n",
    "# You can convert these scores to class labels based on a threshold (e.g., 0.5)\n",
    "predicted_labels = [1 if score >= 0.5 else 0 for score in predictions]\n",
    "\n",
    "class_mapping = {0: \"fake\", 1: \"true\"}\n",
    "\n",
    "# Use the mapping to transform the predicted labels\n",
    "predicted_class_names = [class_mapping[label] for label in predicted_labels]\n",
    "\n",
    "print(predicted_class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80532f8d-3d30-4712-b4c2-9244a2b0e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your trained CNN model\n",
    "model1 = load_model('models/fasttext-cnn-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "054bd367-daee-4562-9a89-d799ccd20475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 227ms/step\n",
      "['fake', 'fake', 'true']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RegexpTokenizer(r'[A-Za-z]+') #to getting alpha only\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Tokenize and preprocess the new input data\n",
    "new_input_data = [\"The fallout from Ryan Lochteâ€™s story about being robbed at gunpoint in Rio  â€”   a tale the Brazilian police said was not true  â€”   continued Monday when four companies said they would end business partnerships with Mr. Lochte, an American swimmer and   Olympic medalist. After a week of intense international media attention and anger in Brazil, the financial repercussions were swift for Mr. Lochte as Speedo USA, the luxury clothing retailer Ralph Lauren and the mattress company Airweave all announced that they would part ways with him. And Syneron Candela, a company that sells   devices, told Reuters its relationship with the swimmer ended on Sunday. Speedo USA said in a message on Twitter that it would instead donate a $50, 000 portion of Mr. Lochteâ€™s fee to a charity to help Brazilian children. â€œWhile we have enjoyed a winning relationship with Ryan for over a decade and he has been an important member of the Speedo team, we cannot condone behavior that is counter to the values this brand has long stood for,â€ the company said in its statement. On Monday, Kim Angelastro, a spokeswoman for Syneron Candela, wrote in an email, â€œWe hold our employees to high standards, and we expect the same of our business partners. â€ Mr. Lochte was a spokesman for the companyâ€™s Gentle Hair Removal brand. Through a spokeswoman, Ralph Lauren said Monday that Mr. Lochteâ€™s endorsement agreement with the clothing company had been for only the 2016 Olympics, and that his contract would not be renewed. Airweave said on Twitter that â€œafter careful consideration, we have made the decision to end our partnership with Ryan Lochte. â€ The decisions to cut ties with Mr. Lochte, 32, were the first major signs of the financial fallout for him. For the past week, he has been at the center of an international firestorm after the Brazilian police said he and three other American athletes  â€”   Jimmy Feigen, Jack Conger and Gunnar Bentz  â€”   had fabricated the account of being robbed after a   party in Rio de Janeiro. The authorities said that the swimmers had instead drunkenly vandalized a gas station bathroom, paying a security guard about $50 for the damage before leaving. Mr. Lochte originally said that the car they were traveling in had been stopped by armed men, who held a gun to his head. But his story later changed. A Brazilian judge ordered the swimmers to remain in Rio, but Mr. Lochte had already left the country. After Mr. Conger and Mr. Bentz were pulled from their flight to the United States, they told the police that the confrontation began when Lochte pulled a poster off a gas station wall. Mr. Feigen, 26, later donated $10, 800 to a charity in Rio that teaches martial arts to poor children. Mr. Lochte first issued an apology on social media  â€”   â€œI should have been much more responsible for how I handled myself,â€ he wrote  â€”   then told Matt Lauer in an interview on NBC that he had been intoxicated and that he had â€œoverexaggerated that story. â€ He has maintained that he was held at gunpoint. â€œAll we know is that there was a gun pointed in our direction, and we were demanded to give money,â€ Mr. Lochte said. Mr. Lochte, whose boyish and sometimes oafish personality had made him a commercial success in Olympics past, had headed into Rio with fewer sponsors than heâ€™d had at the London Games, according to a report by CNN Money. Mr. Lochte took home a gold medal in the   freestyle relay in Rio.\", \"Republicans are working overtime trying to sell their scam of a tax bill to the public as something that directly targets middle-class and working-class families with financial relief. Nothing could be further from the truth, and they re getting hammered on that repeatedly. Speaking on CNBC, Paul Ryan was going full throttle, trying to convince us that the paltry savings we re getting is actually wait for it big money.But he didn t just go with the usual talking points. With a smug look that only someone who grew up in a wealthy family can muster when talking about that which he does not know, Ryan claimed that the $2,059 more per year that families living paycheck-to-paycheck will see is extremely significant. Then he decided he had to amend that to say such savings might be nothing to a family earning $600,000 per year (true), or for people living in New York or California (false).Those are the same two states that Trump s loyal subjects insist on stripping from the 2016 vote totals to claim that Trump actually won the popular vote. Watch Ryan completely dismiss all the struggling families living in blue states below:If you re living paycheck-to-paycheck which is more than half of the people in this country and you got #2059more from a tax cut next year, that s not nothing. pic.twitter.com/8TKtrMqRa1  Paul Ryan (@SpeakerRyan) December 21, 2017Someone needs to reach through their computer or television and wipe that smugness off his face. It is the height of arrogance and insult to imply that there are no struggling families in either of those two states.Featured image via Mark Wilson/Getty Images\",\"BREAKING : Trump Expressed Concern Over Anthony Weinerâ€™s â€œIllegal Accessâ€ to Classified Info 2 Months ago BREAKING : Trump Expressed Concern Over Anthony Weinerâ€™s â€œIllegal Accessâ€ to Classified Info 2 Months ago Breaking News By Amy Moreno October 28, 2016. Once again, Trump was right. Back in August, in a statement regarding Hillaryâ€™s carelessness handling classified documents, Trump stated that he was concerned that Weiner had â€œaccessâ€ to information he shouldnâ€™t. Now that weâ€™re learning that the FBI discovered â€œnew emailsâ€ on a â€œdeviceâ€ associated to Weiner, it looks as if Trump was right AGAIN. â€” Deplorable AJ (@asamjulian) October 28, 2016 This is a movement â€“ we are the political OUTSIDERS fighting against the FAILED GLOBAL ESTABLISHMENT! Join the resistance and help us fight to put America First! Amy Moreno is a Published Author , Pug Lover & Game of Thrones Nerd. You can follow her on Twitter here and Facebook here . Support the Trump Movement and help us fight Liberal Media Bias. Please LIKE and SHARE this story on Facebook or Twitter.  \"]\n",
    "new_sequences = [wordopt(sentence) for sentence in new_input_data]\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer1 = Tokenizer()\n",
    "tokenizer1.fit_on_texts(new_sequences)  # Assuming x_train is a list of text strings\n",
    "new_sequences = tokenizer1.texts_to_sequences(new_sequences)\n",
    "\n",
    "# Pad sequences\n",
    "new_sequences = pad_sequences(new_sequences, maxlen=sequence_length)\n",
    "\n",
    "# new_sequences = [map_tokens_to_indices(sequence, embedding_matrix, sequence_length) for sequence in new_sequences]\n",
    "\n",
    "# Convert 'new_sequences' to a NumPy array\n",
    "new_data = np.array(new_sequences)\n",
    "\n",
    "# Pad or truncate the sequences to match the sequence length\n",
    "new_data = pad_sequences(new_data, maxlen=sequence_length, padding='post', truncating='post')\n",
    "\n",
    "# Make predictions on the new data\n",
    "predictions = model1.predict(new_data)\n",
    "\n",
    "# The 'predictions' array will contain probability scores for each class (0 and 1)\n",
    "# You can convert these scores to class labels based on a threshold (e.g., 0.5)\n",
    "predicted_labels = [1 if score >= 0.5 else 0 for score in predictions]\n",
    "\n",
    "class_mapping = {0: \"fake\", 1: \"true\"}\n",
    "\n",
    "# Use the mapping to transform the predicted labels\n",
    "predicted_class_names = [class_mapping[label] for label in predicted_labels]\n",
    "\n",
    "print(predicted_class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a4c0a-8712-4b67-82ae-9e8c583f68ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917ee73-5a37-46e5-9a23-61d6beeba2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
